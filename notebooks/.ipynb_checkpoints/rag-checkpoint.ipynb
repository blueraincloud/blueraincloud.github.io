{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cdb9025-6c50-43c2-8d13-33dd0c421b61",
   "metadata": {},
   "source": [
    "#  Retrieval-Augmented Generation (RAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0f9aab-a74d-4a3a-a394-19a9cd3290b0",
   "metadata": {},
   "source": [
    "- RAG architectures allow for injecting additional information to a query to augment the knownledge provided by the LLM with domain specific knowledge.\n",
    "- This is often helpful in situations where not sufficient knowledge was available in the corpus of the pretrained model.\n",
    "- Alternatively, fine-tuning can be considered to further train the model on the new data, but this is often resource intensive and requires large data sets of the representative domain.\n",
    "- In this notebook we introduce build a simple RAG architecture to demonstrate the concept and extend it to query DORA regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353cf33-114d-41df-9e2f-fbb5a47bf0e7",
   "metadata": {},
   "source": [
    "![title](https://github.com/blueraincloud/blueraincloud.github.io/blob/main/images/RAG/rag.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b4b88-3562-4038-801e-e844fe526c3e",
   "metadata": {},
   "source": [
    "## Imports and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1aa1e13-f9ca-4118-b9fd-912ed7afdab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f947390-2165-4139-986d-f8792a8dbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n",
    "!pip install bs4\n",
    "!pip install langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab2ca5-9357-4c73-ac90-a08e5259bf09",
   "metadata": {},
   "source": [
    "## Generate a document for the RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1bd78-e252-4e37-9a11-7082d29723da",
   "metadata": {},
   "source": [
    "Firstly, we ask chatGPT generate a document pretending that prompt-engineering has a different definition to its original meaning.\n",
    "It is given a completly bogus meaning, and this is used to check the effects of the RAG on the system.\n",
    "Additionally, a bogus word is made up \"clorkimn\" and given a definition.\n",
    "The document generated is located here:\n",
    "\n",
    "https://github.com/blueraincloud/blueraincloud.github.io/blob/main/misc/rag-text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fccb502-0a89-4c80-a052-27eec8afa8e6",
   "metadata": {},
   "source": [
    "## Fetch the document for the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b354dd-e9c0-49a6-b314-ce9aa667eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document location\n",
    "urls = [\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/misc/rag-text.txt\"\n",
    "]\n",
    "\n",
    "#  User Agent\n",
    "class CustomWebBaseLoader(WebBaseLoader):\n",
    "    def __init__(self, url):\n",
    "        super().__init__(url, requests_kwargs={\"headers\": {\"User-Agent\": \"Mozilla/5.0\"}})\n",
    "\n",
    "# Load document\n",
    "docs = [CustomWebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a7c2ea-3946-4d1c-aa03-39a7e360b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text_splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=200, chunk_overlap=0\n",
    ")\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20823b-5fe6-42c0-829a-0439d121b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(doc_splits, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2524fe4e-df89-4b7f-989c-e2e85a57c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Define the prompt template for the LLM\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following documents to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ca3be1-5dc8-44d7-ab24-e55d4e34fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Llama 3.1\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc888c-0d85-4209-8fab-21d13b6387e6",
   "metadata": {},
   "source": [
    "## Testing base model without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7c9407-0fae-496f-a069-f17656b66224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Prompt-engineering is the process of designing and crafting input prompts to elicit specific, accurate, and relevant responses from language models or AI systems. It involves understanding how to phrase questions, statements, or tasks in a way that maximizes the model's ability to provide helpful and informative answers. Effective prompt-engineering can significantly improve the quality and reliability of AI-generated output.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an assistant for question-answering tasks.\n",
    "            Use short sentences and keep the answer to a max of three sentences.\n",
    "            Question: {question}\n",
    "            Answer:\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is prompt-engineering?\",\n",
    "    }\n",
    ")\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2928bd-ffb5-4b91-b455-edf8414f5ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I couldn\\'t find any information on \"clorkimn\". It\\'s possible it\\'s a misspelling or not a widely known term.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is clorkimn?\",\n",
    "    }\n",
    ")\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f582b-5fa5-4a1f-9cf4-36c74c2e4cd5",
   "metadata": {},
   "source": [
    "As shown in the two prompts above it gives the normal definition for prompt-engineering and it does not know what the made up word \"clorkimn\" means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d6e39-9523-4c76-b1fe-72d0ae3dd48c",
   "metadata": {},
   "source": [
    "## Testing with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99192f5-31de-4b38-b069-b097927b37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Define the prompt template for the LLM\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the documents in question and fall back on the main corpus of knowledge if the documents are insufficient.\n",
    "    Do not mention when you fall back or if it comes from the documents or main corpus of knowledge.\n",
    "    Use short sentences and keep the answer to a max of three sentences.\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97bc393e-daa4-4489-b8e8-8ac55367866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain combining the prompt template and LLM\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f2af3d-8d61-4dca-8e7b-1a57a6e9f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG application\n",
    "class RAGApplication:\n",
    "    def __init__(self, retriever, rag_chain):\n",
    "        self.retriever = retriever\n",
    "        self.rag_chain = rag_chain\n",
    "    def run(self, question):\n",
    "        # Retrieve documents\n",
    "        documents = self.retriever.invoke(question)\n",
    "        # Extract content documents\n",
    "        doc_texts = \"\\\\n\".join([doc.page_content for doc in documents])\n",
    "        # Invoke LLM\n",
    "        answer = self.rag_chain.invoke({\"question\": question, \"documents\": doc_texts})\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a63c0e4-24d0-4fd6-8e7b-b87c661edbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Prompt engineering\n",
      "Answer: Prompt engineering is a way of life that cultivates awareness, fosters creativity, and connects people through shared experiences. It involves harnessing the power of thoughts and feelings to connect with the universe by crafting effective questions. This practice unlocks the treasures of one's mind and reveals the richness of their thoughts and feelings.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RAG application\n",
    "rag_application = RAGApplication(retriever, rag_chain)\n",
    "# Example usage\n",
    "question = \"What is Prompt engineering\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d4afde1-3828-4324-aff0-11d4bc2b6058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is clorkimn?\n",
      "Answer: Clorkimn is the color of time. It originates from the English words clorkimness, which is not a made-up term. Clorkimn is an uncommon word that was lost in translation but holds importance.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is clorkimn?\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad7c4d-7383-40fb-8844-c0201904449a",
   "metadata": {},
   "source": [
    "## DORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edbf5a-c7fb-4b56-8a45-82a64a4ddbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Windows; Windows x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36'}\n",
    "\n",
    "url = 'https://www.url_of_pdf_file.com/sample.pdf'\n",
    "response = requests.get(url=url, headers=headers, timeout=120)\n",
    "on_fly_mem_obj = io.BytesIO(response.content)\n",
    "pdf_file = PdfReader(on_fly_mem_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0a73d0d-2047-4206-9ca4-1b9694888532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required classes\n",
    "import requests\n",
    "import io\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document  # Import the Document class\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Windows; Windows x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36'}\n",
    "\n",
    "doc_names = [\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/a.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/b.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/c.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/d.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/e.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/f.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/g.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/h.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/i.pdf?raw=true\",\n",
    "    \"https://github.com/blueraincloud/blueraincloud.github.io/blob/main/resources/RAG/j.pdf?raw=true\"\n",
    "]\n",
    "\n",
    "corpus = []\n",
    "for adoc in doc_names:\n",
    "    # Fetch and process PDF\n",
    "    response = requests.get(url = adoc, headers=headers, timeout=120)\n",
    "    on_fly_mem_obj = io.BytesIO(response.content)\n",
    "    \n",
    "    reader = PdfReader(on_fly_mem_obj)\n",
    "\n",
    "    # Extract text\n",
    "    # print(page.extract_text())\n",
    "\n",
    "    docs_list = [Document(page_content=doc.extract_text()) for doc in reader.pages]\n",
    "    corpus = corpus + docs_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c9ec046-f276-4aa7-b5fc-0e7f7f03c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=200, chunk_overlap=0\n",
    ")\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78b2818c-b7ba-4bde-a4d2-a6101212f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "vectorstore = FAISS.from_documents(doc_splits, HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dd2e0a7-5a26-4f30-83cc-3dd324d51681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don\\'t have any documents related to a \"DORA act\". Could you please provide more context or information about what DORA act refers to? I\\'ll do my best to find relevant documents and answer your question. \\n\\nHowever, after some research, I found that the Digital Operational Resilience Act (DORA) is a proposed EU regulation aimed at strengthening the operational resilience of financial institutions. If this is the correct context, please let me know and I can try to provide more information based on available documents.\\n\\nPlease note that my previous response was incorrect, and I\\'m trying to correct it now.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an assistant for question-answering tasks. \\\n",
    "            Use the following documents to answer the question.\\\n",
    "            If you don't know the answer, just say that you don't know.\\\n",
    "            In general you are dealing with regulatory documents and often it is verbose. Giving a summary would be helpful.\\\n",
    "            Each document typicall has a background and rational and a technical standards section.\\\n",
    "            WHen giving answer back focus on the content in the technical standards section.\\\n",
    "            THe background and rational and other sections are not as important:\\\n",
    "            Question: {question}\\\n",
    "            Answer:\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is DORA act about?\",\n",
    "    }\n",
    ")\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e0e5ef4-766e-4281-8727-ef7b009daac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. \\\n",
    "            Use the following documents to answer the question.\\\n",
    "            If you don't know the answer, just say that you don't know.\\\n",
    "            In general you are dealing with regulatory documents and often it is verbose. Giving a summary would be helpful.\\\n",
    "             Each document typicall has a section where responds give their feedback and a section where the actual draft of standards are given.\\\n",
    "            When summarizing this information only consider the actual standards that are set and ignore the other sections:\\\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b87d38fc-8f88-4ddd-a2d0-6e47c5eca37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is DORA act about?\n",
      "Answer: Based on the provided documents, I can summarize that DORA is about regulations related to the oversight of financial entities and ICT third-party service providers.\n",
      "\n",
      "The actual standards set by DORA include:\n",
      "\n",
      "* Tests organized at the level of a financial entity by the TLPT authority of its home Member State (point 75)\n",
      "* Requirements for competent authorities in relation to the joint examination team (point c)\n",
      "\n",
      "These regulations are outlined in two separate Regulatory Technical Standards (RTS) under DORA.\n",
      "\n",
      "As for what DORA is about, I can provide a brief summary:\n",
      "\n",
      "DORA appears to be an act that regulates the oversight of financial entities and ICT third-party service providers. It sets standards for tests and examinations to be conducted by competent authorities, with a focus on ensuring the stability and security of the financial system.\n"
     ]
    }
   ],
   "source": [
    "# Create a chain combining the prompt template and LLM\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "rag_application = RAGApplication(retriever, rag_chain)\n",
    "# Example usage\n",
    "question = \"What is DORA act about?\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da3884db-a345-4aaa-ad0a-75fd76c2fe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Can you give me a one page summary of the documents\n",
      "Answer: Here is a one-page summary of the documents:\n",
      "\n",
      "**Summary**\n",
      "\n",
      "The European Securities and Markets Authority (ESAs) has made some changes to provide more clarity in the draft regulatory technical standards (RTS). The main points are:\n",
      "\n",
      "* **Electronic format**: The report must be in a searchable electronic format, but no specific document type is mandated.\n",
      "* **Content requirements**: The report should include minimum elements, but entities can add other useful information as long as they cover the required content.\n",
      "* **Contractual structure and documentation**: Option A has been retained, which prescribes fields for contractual structure (documentation management).\n",
      "\n",
      "**Key Changes**\n",
      "\n",
      "The ESAs have introduced some changes to provide more clarity, including:\n",
      "\n",
      "* Deleting unnecessary text\n",
      "* Providing more flexibility in electronic format requirements\n",
      "* Emphasizing that the report is not an exhaustive list, but rather a minimum requirement\n",
      "\n",
      "Note: I've only considered the actual standards set and ignored other sections such as feedback and draft documents.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"Can you give me a one page summary of the documents\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e94c23a-a3f0-4e13-8a2c-443f7aa88a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the register of information\n",
      "Answer: Based on the documents provided, here is a summary of what I found regarding the \"register of information\":\n",
      "\n",
      "**Summary:** The register of information is composed of 15 templates that are linked together using relational keys. The templates cover three purposes: (i) ICT risk management; (ii) reporting and disclosure; and (iii) supervision.\n",
      "\n",
      "**Key Components:**\n",
      "\n",
      "1. **Templates**: There are 15 templates in total, which are linked to each other using relational keys.\n",
      "2. **Relational Keys**: Some of the relational keys used include:\n",
      "\t* Contractual arrangement reference number\n",
      "\t* LEI (Legal Entity Identifier) of the entity making use of ICT services\n",
      "\t* ICT third-party service provider identifier\n",
      "\t* Function identifier\n",
      "\t* Type of ICT services (provided in Annex III)\n",
      "3. **Purpose**: The register of information serves three purposes:\n",
      "\t* ICT risk management\n",
      "\t* Reporting and disclosure\n",
      "\t* Supervision\n",
      "\n",
      "**Standards:**\n",
      "\n",
      "1. Financial entities must ensure that the register of information includes required information for all ICT services provided by direct ICT third-party providers (Article 3, Chapter II).\n",
      "2. The register of information shall be maintained and updated to include the required information in relation to all ICT services provided by direct ICT third-party providers.\n",
      "\n",
      "I hope this summary is helpful! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"What is the register of information\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca49844-5beb-46d3-8ded-d74e72a97ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "question = \"What can you tell me about the standards on classifying ICT related incidients\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dbe631-2bd4-48d1-aa49-950c66387623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "question = \"What can you tell me about the RTS on ICT services supporting critical or important functions\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2ffda-a6c2-4c50-886b-60bbee6a92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "question = \"What can you tell me about the risk management framework and simplified risk management framework. What are the main differences? Ignore the correspondance and give me the standards\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8bc661-8056-4612-89eb-ab939467ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "question = \"TLPT is threat led penetration testing. What can you tell me about the TLPT. What are the main differences?\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3ab3b-c790-4c45-b8dc-e1c409d65389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "question = \"How does DORA treat estimation of aggregated annual costs and losses caused by major ICT-related incidents?\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42b2c2-caba-42d0-b79d-a5a01488643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "question = \"What does DORA say about third-party risk management and contract management?\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52f7d9-4d99-4e2a-a20e-e351be9664d6",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d57325-8668-4002-8fb1-89951dc98533",
   "metadata": {},
   "source": [
    "* Evaluation metrics\n",
    "* Fine-tuning comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269268d-fa3c-488e-bf4a-3c6aee91a6bf",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20b0be-40c5-4bb5-b9d7-d31ae09306e7",
   "metadata": {},
   "source": [
    " - https://github.com/meta-llama/llama-recipes/blob/main/recipes/quickstart/Getting_to_know_Llama.ipynb\n",
    " - https://www.datacamp.com/tutorial/llama-3-1-rag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
